---
#######################################
### THIS FILE IS MANAGED BY ANSIBLE ###
###    PLEASE MAKE CHANGES THERE    ###
#######################################

###############################################################################################
#               Core objects like volumes and networks are declared in this file              #
###############################################################################################

###############################################################################################
#      There is no need to create any networks/volumes outside this docker-compose file.      #
#   You may customize the network subnets (192.168.90.0/24 and 91.0/24) below as you please.  #
#        Also same with volumes. I use NFS mounts on my synology NAS, you do you boo          #
###############################################################################################

version: "3.7"

########################### EXTENSION FIELDS

# Default TZ, uid and pid
# To use this put this block in your service: "<<: *default-tz-uid-gid"
x-environment: &default-tz-uid-gid
  TZ: $TZ
  PUID: $PUID
  PGID: $PGID

# To use this put this block in your service: "<<: *logging"
x-logging: &logging
  logging:
    driver: loki
    options:
      loki-url: "http://${SERVER_IP}:${LOKI_PORT}/loki/api/v1/push"

########################### NETWORKS
# Docker Compose version 3.5 or higher required to define networks this way.

networks:
  defaulty:
    name: defaulty
    driver: bridge
  traefik_proxy:
    name: traefik_proxy
    driver: bridge
    # To setup a subnet and allow certain containers to gain a static ip in it
    # Useful for connecting containers that won't have open ports running behind traefik so you can specify the static IP of the container
    ipam:
      config:
        - subnet: 192.168.90.0/24
  socket_proxy:
    name: socket_proxy
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.91.0/24

########################### VOLUMES

volumes:
  tv:
    driver_opts:
      type: "nfs"
      o: "addr=${NAS_IP},wsize=65536,rsize=65536,timeo=60,nolock,soft,rw"
      device: ":${NAS_TV_PATH}"
  movies:
    driver_opts:
      type: "nfs"
      o: "addr=${NAS_IP},wsize=65536,rsize=65536,timeo=60,nolock,soft,rw"
      device: ":${NAS_MOVIES_PATH}"
  downloads:
    driver_opts:
      type: "nfs"
      o: "addr=${NAS_IP},wsize=65536,rsize=65536,timeo=60,nolock,soft,rw"
      device: ":${NAS_DOWNLOADS_PATH}"

########################### SECRETS

secrets:
  htpasswd:
    file: ${DOCKERDIR}/secrets/htpasswd
  cloudflare_email:
    file: ${DOCKERDIR}/secrets/cloudflare_email
  cloudflare_api_key:
    file: ${DOCKERDIR}/secrets/cloudflare_api_key
  plex_claim:
    file: ${DOCKERDIR}/secrets/plex_claim
  traefik_pilot_token:
    file: ${DOCKERDIR}/secrets/traefik_pilot_token
  gmail_email:
    file: ${DOCKERDIR}/secrets/gmail_address
  # This gmail password needs to be the APPLICATION password, not your main login one.
  # https://support.google.com/accounts/answer/185833?hl=en
  gmail_app_pass:
    file: ${DOCKERDIR}/secrets/gmail_app_pass
  services_username:
    file: ${DOCKERDIR}/secrets/services_username
  services_password:
    file: ${DOCKERDIR}/secrets/services_password

########################### SERVICES

services:
  # Traefik 2 - Reverse Proxy
  # https://hub.docker.com/_/traefik
  traefik:
    container_name: traefik
    image: traefik:v2.7
    init: true
    restart: always
    healthcheck:
      test: nc -z localhost 80
      interval: 60s
      timeout: 3s
      retries: 3
    networks:
      traefik_proxy:
        ipv4_address: 192.168.90.254 # You can specify a static IP - I also created a non-proxied DNS record like 'traefik-dc.domain.com' pointing to this IP so i don't need to reference this all the time.
      socket_proxy:
    security_opt:
      - no-new-privileges:true
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 9093
        published: 9093
        protocol: tcp
        mode: host
    volumes:
      - ${DOCKERDIR}/appdata/traefik/rules:/rules
      # - /var/run/docker.sock:/var/run/docker.sock:ro    # Use Docker Socket Proxy instead for improved security
      - ${DOCKERDIR}/appdata/traefik/acme/acme.json:/acme.json    # cert location - you must touch this file and change permissions to 600
      - /var/log/traefik:/var/log # for fail2ban - make sure to touch file before starting container
    environment:
      - CF_API_EMAIL_FILE=/run/secrets/cloudflare_email
      - CF_API_KEY_FILE=/run/secrets/cloudflare_api_key
      - HTPASSWD_FILE=/run/secrets/htpasswd               # HTPASSWD_FILE can be whatever as it is not used/called anywhere.
      - TZ=${TZ}
    secrets:
      - cloudflare_email
      - cloudflare_api_key
      - htpasswd
    command: # CLI arguments
      - --global.checkNewVersion=true
      # - --global.sendAnonymousUsage=true
      - --entryPoints.http.address=:80
      - --entryPoints.https.address=:443
      # Allow these IPs to set the X-Forwarded-* headers - Cloudflare IPs: https://www.cloudflare.com/ips/
      - --entrypoints.https.forwardedHeaders.trustedIPs=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/2
      - --entryPoints.dashboard.address=:9093
      - --api=true
      - --api.dashboard=true
      ##############################################
      ### COMMENT THIS OUT AFTER AUTH IS WORKING ###
      ##############################################
      # - --api.insecure=true # We want to use basic auth for now, then test oauth container and do it that way after.
      # This is enabled for my proxmox gui - I use self-signed certs and it doesn't have an http endpoint.
      # I also want to ensure everything is behind oauth and using a TCP traefik router doesn't allow for middlewares.
      # Skipping cert verification checks behind traefik is a better option than disabling oauth imo as it requires a man in the middle attack from behind traefik/oauth.
      - --serversTransport.insecureSkipVerify=true
      - --pilot.token=$TRAEFIK_PILOT_TOKEN
      - --log=true
      - --log.format=json
      - --log.level=INFO # (Default: error) DEBUG, INFO, WARN, ERROR, FATAL, PANIC
      - --log.filePath=/var/log/traefik.log
      - --accessLog=true
      - --accessLog.format=json
      - --accessLog.filePath=/var/log/access.log
      - --accessLog.bufferingSize=100 # Configuring a buffer of 100 lines
      # - --accessLog.filters.statusCodes=400-499
      - --providers.docker=true
      # Use this docker socket if you are not using a docker socket proxy
      # - --providers.docker.endpoint=unix:///var/run/docker.sock
      # Use this docker socket if you have the secure socket-proxy
      - --providers.docker.endpoint=tcp://socket-proxy:2375
      # Automatically set host rule for services
      # - --providers.docker.defaultrule=Host(`{{ index .Labels "com.docker.compose.service" }}.$DOMAINNAME`) # defines what routing rule to apply to a container if no rule is defined by a label
      - --providers.docker.exposedByDefault=false # If set to false, containers that do not have a traefik.enable=true label are ignored from the resulting routing configuration. Default = true
      # Add dns-cloudflare as default certresolver for all services. Also enables TLS and no need to specify on individual services
      - --entrypoints.https.http.tls.certresolver=dns-cloudflare
      - --entrypoints.https.http.tls.domains[0].main=$DOMAINNAME
      - --entrypoints.https.http.tls.domains[0].sans=*.$DOMAINNAME
      - --providers.docker.network=traefik_proxy # Defines a default docker network to use for connections to all containers
      - --providers.docker.swarmMode=false
      - --providers.file.directory=/rules # Load dynamic configuration from one or more .toml or .yml files in a directory.
      # - --providers.file.filename=/path/to/file # Load dynamic configuration from a file.
      - --providers.file.watch=true # Only works on top level files in the rules folder
      #######################
      ### COMMENT IN PROD ###
      #######################
      # - --certificatesResolvers.dns-cloudflare.acme.caServer=https://acme-staging-v02.api.letsencrypt.org/directory # Set LetsEncrypt Staging Server
      - --certificatesResolvers.dns-cloudflare.acme.email=$CLOUDFLARE_EMAIL
      - --certificatesResolvers.dns-cloudflare.acme.storage=/acme.json
      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.provider=cloudflare
      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.resolvers=1.1.1.1:53,1.0.0.1:53
      #########################
      ### UNCOMMENT IN PROD ###
      #########################
      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.delayBeforeCheck=90 # To delay DNS check and reduce LE hitrate
    labels:
      #- "autoheal=true"
      - "traefik.enable=true"
      ## HTTP-to-HTTPS Redirect ##
      # - "traefik.http.routers.http-catchall.entrypoints=http"
      # - "traefik.http.routers.http-catchall.rule=HostRegexp(`{host:.+}`)"
      # - "traefik.http.routers.http-catchall.middlewares=redirect-to-https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"  # Redirect all requests to HTTPS
      ## HTTP Routers ##
      - "traefik.http.routers.traefik-rtr.entrypoints=https"
      - "traefik.http.routers.traefik-rtr.rule=Host(`traefik.$DOMAINNAME`)"
      ## Services - API ##
      - "traefik.http.routers.traefik-rtr.service=api@internal"
      ## Middlewares ##
      # - "traefik.http.routers.traefik-rtr.middlewares=chain-basic-auth@file"
      - "traefik.http.routers.traefik-rtr.middlewares=chain-oauth@file"
    extra_hosts:
      - host.docker.internal:172.17.0.1  # Command to find this ip: `docker network inspect bridge`. Resource -> https://gist.github.com/gaieges/936bdf91e01e4cc782eb047e5873089b
    <<: *logging

  # Watchtower - updates containers with latest images
  # https://hub.docker.com/r/containrrr/watchtower
  watchtower:
    container_name: watchtower
    image: containrrr/watchtower
    init: true
    restart: always
    networks:
      - defaulty
      - socket_proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      TZ: ${TZ}
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_REMOVE_VOLUMES: "true"
      WATCHTOWER_INCLUDE_STOPPED: "true"
      WATCHTOWER_NO_STARTUP_MESSAGE: "false"
      WATCHTOWER_SCHEDULE: "0 30 4 * * *" # Everyday at 04:30
      # WATCHTOWER_POLL_INTERVAL: ${WATCHTOWER_INTERVAL}  # NOTE: Only interval or schedule can be defined, NOT BOTH!
      WATCHTOWER_TIMEOUT: 15
      WATCHTOWER_NOTIFICATIONS_LEVEL: info
      # WATCHTOWER_NOTIFICATIONS: shoutrrr
      # Using Pushbullet, telegram and pushover as examples, but just pick one
      # WATCHTOWER_NOTIFICATION_URL: "pushover://shoutrrr:$PUSHOVER_APP_API__SECRET@$PUSHOVER_USER_API__SECRET/?devices=$PUSHOVER_DEVICE telegram://$TELEGRAM_BOT_TOKEN__SECRET@telegram?channels=$TELEGRAM_CHAT_ID__SECRET pushbullet://$PUSHBULLET_API__SECRET"
      # Or email:
      #- WATCHTOWER_NOTIFICATIONS=email
      #- WATCHTOWER_NOTIFICATION_EMAIL_FROM=${EMAIL_FROM}
      #- WATCHTOWER_NOTIFICATION_EMAIL_TO=${WATCHTOWER_EMAIL_TO}
      #- WATCHTOWER_NOTIFICATION_EMAIL_SERVER=${SMTP_SERVER}
      #- WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=${SMTP_PORT}
      #- WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=${SMTP_USER}
      #- WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=${SMTP_PASSWORD}
      DOCKER_HOST: tcp://socket-proxy:2375
    <<: *logging

  # https://hub.docker.com/r/willfarrell/autoheal/
  autoheal:
    container_name: autoheal
    image: willfarrell/autoheal
    init: true
    restart: always
    environment:
      - AUTOHEAL_CONTAINER_LABEL=all    # To watch all containers
      - TZ=${TZ}
    volumes:
      - '/var/run/docker.sock:/var/run/docker.sock'
    <<: *logging

  # Docker Socket Proxy - Security Enchanced Proxy for Docker Socket
  # https://hub.docker.com/r/tecnativa/docker-socket-proxy
  socket-proxy:
    container_name: socket-proxy
    image: tecnativa/docker-socket-proxy
    init: true
    restart: always
    healthcheck:
      test: nc -z localhost 2375
      interval: 60s
      timeout: 3s
      retries: 3
    networks:
      socket_proxy:
        ipv4_address: 192.168.91.254 # You can specify a static IP - I also created a non-proxied DNS record like 'socket-proxy-dc.domain.com' pointing to this IP so i don't need to reference this all the time.
    privileged: true
    ports:
    - "127.0.0.1:2375:2375" # Port 2375 should only ever get exposed to the internal network. When possible use this line.
    # I use the next line instead, as I want portainer to manage multiple docker endpoints within my home network.
    # - "2375:2375"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    environment:
      - LOG_LEVEL=info # debug,info,notice,warning,err,crit,alert,emerg
      ## Variables match the URL prefix (i.e. AUTH blocks access to /auth/* parts of the API, etc.).
      # 0 to revoke access.
      # 1 to grant access.
      ## Granted by Default
      - EVENTS=1
      - PING=1
      - VERSION=1
      ## Revoked by Default
      # Security critical
      - AUTH=0
      - SECRETS=0
      - POST=1              # Watchtower
      - DELETE=1            # Watchtower
      # GET Optons
      - BUILD=0
      - COMMIT=0
      - CONFIGS=0
      - CONTAINERS=1        # Traefik, portainer, etc.
      - DISTRIBUTION=0
      - EXEC=0
      - IMAGES=1            # Portainer, Watchtower
      - INFO=1              # Portainer
      - NETWORKS=1          # Portainer, Watchtower
      - NODES=0
      - PLUGINS=0
      - SERVICES=1          # Portainer
      - SESSION=0
      - SWARM=0
      - SYSTEM=0
      - TASKS=1             # Portaienr
      - VOLUMES=1           # Portainer
      # POST Options
      - CONTAINERS_CREATE=1 # WatchTower
      - CONTAINERS_START=1  # WatchTower
      - CONTAINERS_UPDATE=1 # WatchTower
      # DELETE Options
      - CONTAINERS_DELETE=1 # WatchTower
      - IMAGES_DELETE=1     # WatchTower
    <<: *logging

  # Grafana - Graphical data visualization for InfluxDB data
  # https://hub.docker.com/r/grafana/grafana
  grafana:
    container_name: grafana
    # Using ubuntu image instead of alpine because of the plugin `grafana-image-renderer` only being available on ubuntu. Revert back to `latest` if they fix this -> https://grafana.com/docs/grafana/latest/installation/docker/#build-with-grafana-image-renderer-plugin-pre-installed
    image: grafana/grafana:8.5.2
    init: true
    restart: unless-stopped
    # healthcheck:
    #   test: curl -sI http://localhost:3000
    #   interval: 60s
    #   timeout: 3s
    #   retries: 3
    networks:
      traefik_proxy:
        ipv4_address: 192.168.90.151 # You can specify a static IP - I also created a non-proxied DNS record like 'transmission-dc.domain.com' pointing to this IP so i don't need to reference this all the time.
      defaulty: ~
    security_opt:
      - no-new-privileges:true
    ports:
      - "$GRAFANA_PORT:3000"
    user: "0"
    # depends_on:
    #   influxdb:
    #     condition: service_healthy
    volumes:
      - ${DOCKERDIR}/appdata/grafana:/var/lib/grafana
      # - ${DOCKERDIR}/grafana/logs:/var/log/grafana  # Logging file when debugging. Disable in prod.
      # Skipped to using environment vars below instead of mapping config.ini
      # - ${DOCKERDIR}/grafana/config/grafana.ini:/etc/grafana/grafana.ini # Mount the grafana config as well to make changes to it.
    secrets:
      - gmail_email
      - gmail_app_pass
      - services_username
      - services_password
    environment:
      # I use ENV vars instead of mapping the config file - RTFM on how to set them up for ANY config:
      # https://grafana.com/docs/grafana/latest/administration/configuration/#override-configuration-with-environment-variables
      TZ: ${TZ}
      # Add plugin from github like: https://github.com/Aryido/grafana-jsontext-panel/releases/download/v1.2.2-beta/fondus-jsonpretty-panel.zip; fondus-jsonpretty-panel
      GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource,grafana-worldmap-panel,grafana-piechart-panel"  # This plugin causes issues so removed it: grafana-image-renderer
      # GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: fondus-jsonpretty-panel    # https://github.com/Fondus/Grafana-JsonPretty-Panel#faq
      # Some config items:
      GF_SERVER_DOMAIN: "grafana.${DOMAINNAME}"
      GF_SERVER_ROOT_URL: "https://grafana.${DOMAINNAME}"
      # Admin User setup
      GF_SECURITY_ADMIN_USER__FILE: "/run/secrets/services_username"
      GF_SECURITY_ADMIN_PASSWORD__FILE: "/run/secrets/services_password"
      # Home Assistant iframe integration (we use google oauth in front of everything on the reverse proxy, so we should be fine)
      # GF_AUTH_DISABLE_LOGIN_FORM: "true"
      # GF_AUTH_ANONYMOUS_ENABLED: "true"
      # GF_AUTH_ANONYMOUS_ORG_ROLE: "Viewer"
      # GF_SECURITY_ALLOW_EMBEDDING: "true"
      # Using Gmail SMTP for alerts
      GF_SMTP_ENABLED: "true"
      GF_SMTP_HOST: "smtp.gmail.com:587"
      GF_SMTP_SKIP_VERIFY: "true"
      GF_SMTP_FROM_NAME: "Grafana"
      GF_SMTP_FROM_ADDRESS: "admin@grafana.${DOMAINNAME}"
      GF_SMTP_USER__FILE: "/run/secrets/gmail_email"
      GF_SMTP_PASSWORD__FILE: "/run/secrets/gmail_app_pass"
      # Grafana 8 alerting enable
      GF_UNIFIED_ALERTING_ENABLED: "true"
      GF_ALERTING_ENABLED: "false"
      # Log level/mode - Disable all logging env vars in prod (https://grafana.com/docs/grafana/latest/administration/configuration/#log)
      # GF_LOG_MODE: "console file" # Log to both console and file.
      # GF_LOG_LEVEL: "debug"
    labels:
      - "traefik.enable=true"
      ## HTTP Routers
      - "traefik.http.routers.grafana-rtr.entrypoints=https"
      - "traefik.http.routers.grafana-rtr.rule=Host(`grafana.$DOMAINNAME`)"
      ## Middlewares
      - "traefik.http.routers.grafana-rtr.middlewares=chain-oauth@file"
      ## HTTP Services
      - "traefik.http.routers.grafana-rtr.service=grafana-svc"
      - "traefik.http.services.grafana-svc.loadbalancer.server.port=3000"
    <<: *logging

  # https://hub.docker.com/r/grafana/loki
  loki:
    container_name: loki
    image: grafana/loki:2.5.0
    init: true
    restart: unless-stopped
    healthcheck:
      test: nc -z localhost 3100
      interval: 60s
      timeout: 3s
      retries: 3
    networks:
      traefik_proxy:
        ipv4_address: 192.168.90.250
    ports:
      - "${LOKI_PORT}:3100"
    volumes:
      - ${DOCKERDIR}/appdata/loki/config/:/etc/loki
      - ${DOCKERDIR}/appdata/loki/data:/data/loki
    command: -config.file=/etc/loki/loki-config.yaml

  # https://hub.docker.com/r/grafana/promtail
  promtail:
    container_name: promtail
    image: grafana/promtail:2.5.0
    init: true
    restart: unless-stopped
    # healthcheck:
    #   test: pidof promtail
    #   interval: 60s
    #   timeout: 3s
    #   retries: 3
    volumes:
      - /var/log:/var/log
      - ${DOCKERDIR}/appdata/promtail/etc:/etc/promtail
    ports:
      - "9080:9080" # for http web interface
      - "1514:1514" # for syslog-ng
    command: -config.file=/etc/promtail/config.yml
    networks:
      - traefik_proxy
    <<: *logging

  # MariaDB - MySQL Database
  # https://hub.docker.com/r/linuxserver/mariadb/
  # After starting container for the first time, if you ran the ansible playbook, it will have created a file to bootstrap it: `templates/docker/appdata/mariadb/config/initdb.d/authelia.sql`
  mariadb:
    container_name: mariadb
    image: lscr.io/linuxserver/mariadb:10.5.15
    # init: true
    restart: unless-stopped
    # network_mode: host
    networks:
      - defaulty
    healthcheck:
      test: ["CMD", 'mysqladmin', 'ping', '-h', 'localhost', '-u', 'root', '-p$$MYSQL_ROOT_PASSWORD']
      interval: 20s
      timeout: 10s
      retries: 10
    ports:
      - "${MARIADB_PORT}:3306"
    volumes:
      - ${DOCKERDIR}/appdata/mariadb:/config   # Contains the db itself and all assorted settings.
    environment:
      MYSQL_ROOT_PASSWORD: ${MARIADB_ROOT_PASSWORD}   # Set this to root password for installation (minimum 4 characters).
      MYSQL_DATABASE: ${MARIADB_DATABASE}             # Specify the name of a database to be created on image startup (I created hass).
      MYSQL_USER: ${MARIADB_USER}                     # This user will have superuser access to the database specified by MYSQL_DATABASE above (do not use root here), (I created hass).
      MYSQL_PASSWORD: ${MARIADB_PASSWORD}             # Set this to the password you want to use for you MYSQL_USER above (minimum 4 characters) (I did for hass user)..
      <<: *default-tz-uid-gid
    <<: *logging

  # InfluxDB - Database for sensor data
  # Create influxdb.conf
  # https://hub.docker.com/_/influxdb
  influxdb:
    container_name: influxdb
    image: influxdb:2.2
    init: true
    restart: always
    healthcheck:
      test: curl -sI http://127.0.0.1:8086
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      - traefik_proxy
    security_opt:
      - no-new-privileges:true
    ports:
      - "${INFLUXDB_PORT}:8086"
    volumes:
      - ${DOCKERDIR}/appdata/influxdb/config:/etc/influxdb2
      - ${DOCKERDIR}/appdata/influxdb/data:/var/lib/influxdb2
      - ${DOCKERDIR}/appdata/influxdb/init_scripts/:/docker-entrypoint-initdb.d   # Bucket initialization script + bootstrapping influxdb
    environment:
      - TZ=${TZ}
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${SERVICES_USERNAME}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${SERVICES_PASSWORD}
      - DOCKER_INFLUXDB_INIT_ORG=home
      - DOCKER_INFLUXDB_INIT_BUCKET=hass
      - DOCKER_INFLUXDB_INIT_RETENTION=26w # Change this to however many weeks you want influxdb to retain data on the initial bucket created. Omit to store data indefinitely.
      # # Logging queries for troubleshooting - DOESN'T CURRENTLY WORK and no idea why? :sadface:
      # - INFLUXDB_DATA_QUERY_LOG_ENABLED=true
      # - INFLUXDB_DATA_TRACE_LOGGING_ENABLED=true
      # - INFLUXDB_HTTP_LOG_ENABLED=true
      # # Log level: error, warn, info, debug
      # - INFLUXDB_LOGGING_LEVEL=debug
    labels:
      - "traefik.enable=true"
      ## HTTP Routers
      - "traefik.http.routers.influxdb-rtr.entrypoints=https"
      - "traefik.http.routers.influxdb-rtr.rule=Host(`influxdb.$DOMAINNAME`)"
      ## Middlewares
      - "traefik.http.routers.influxdb-rtr.middlewares=chain-oauth@file"
      ## HTTP Services
      - "traefik.http.routers.influxdb-rtr.service=influxdb-svc"
      - "traefik.http.services.influxdb-svc.loadbalancer.server.port=8086"
    <<: *logging

  # Cloudflare DDNS - Dynamic DNS Updater to update my WAN IP if it ever changes
  # https://hub.docker.com/r/oznu/cloudflare-ddns/
  cf-ddns:
    container_name: cf-ddns
    image: oznu/cloudflare-ddns:latest
    init: true
    restart: always
    healthcheck:
      test: ps aux | grep -q [c]rond  # container is a cron job
      interval: 60s
      timeout: 3s
      retries: 3
    security_opt:
      - no-new-privileges:true
    environment:
      API_KEY: $CLOUDFLARE_API_TOKEN
      ZONE: $DOMAINNAME
      PROXIED: "true"
      RRTYPE: A
      DELETE_ON_STOP: "false"
      DNS_SERVER: 1.1.1.1
    <<: *logging

  # UniFi Controller - Managing UniFi Network
  # https://hub.docker.com/r/linuxserver/unifi-controller
  unifi:
    container_name: unifi
    image: linuxserver/unifi-controller
    # init: true
    restart: always
    healthcheck:
      test: curl -sI http://localhost:8443  # Healthcheck works on the IP associated with the container
      interval: 60s
      timeout: 3s
      retries: 3
    networks:
      traefik_proxy:
        ipv4_address: 192.168.90.153 # You can specify a static IP
    security_opt:
      - no-new-privileges:true
    ports:
      - 3478:3478/udp # Required - Unifi STUN port
      - 10001:10001/udp # Required - Device discovery
      - 8080:8080 # Required - Device and controller communication
      - 8443:8443 # Required - Web GUI/API port
      # - 1900:1900/udp # optional - Required for `Make controller discoverable on L2 network` option - Currently clashes with plex DLNA
      - 8843:8843 # optional - Guest portal HTTPS redirect port
      - 8880:8880 # optional - Guest portal HTTP redirect port
      - 6789:6789 # optional - Mobile throughput/speed test
      # - 5514:5514/udp # optional - Remote syslog capture
      # - 27117:27117/tcp # optional - local-bound database communication
      # UDP 5656-5699 Ports used by AP-EDU broadcasting.
    volumes:
      - ${DOCKERDIR}/appdata/unifi:/config
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      <<: *default-tz-uid-gid
      # MEM_LIMIT: 1024M # Optionally change the Java memory limit (-Xmx) (default is 1024M).
      # MEM_STARTUP: 1024M # Optionally change the Java initial memory (-Xms) (default is 1024M).
    labels:
      - "traefik.enable=true"
      ## HTTP Routers Auth
      - "traefik.http.routers.unifi-rtr.entrypoints=https"
      - "traefik.http.routers.unifi-rtr.rule=Host(`unifi.$DOMAINNAME`)"
      - "traefik.http.routers.unifi-rtr.priority=99"
      ## Middlewares
      - "traefik.http.routers.unifi-rtr.middlewares=chain-oauth@file"
      ## HTTP Services
      - "traefik.http.routers.unifi-rtr.tls=true"
      - "traefik.http.routers.unifi-rtr.tls.certresolver=dns-cloudflare"
      - "traefik.http.routers.unifi-rtr.service=unifi-svc"
      - "traefik.http.services.unifi-svc.loadbalancer.server.scheme=https"
      - "traefik.http.services.unifi-svc.loadbalancer.server.port=8443"
    <<: *logging
